# ToDoApp - Autoscaling Demo en GCP con Ansible

> **DemostraciÃ³n de autoscaling automÃ¡tico en Kubernetes (GKE) usando Ansible como IaC**

AplicaciÃ³n web de tareas (ToDo) desplegada completamente en **Google Kubernetes Engine (GKE)** utilizando **Ansible** como Ãºnica herramienta de Infrastructure as Code. Incluye autoscaling horizontal de pods (HPA) y autoscaling de nodos del cluster (Cluster Autoscaler).

---

## ğŸ¯ Lo Importante: Despliegue con Ansible

Este proyecto estÃ¡ diseÃ±ado para **desplegar toda la infraestructura con Ansible**, desde cero hasta producciÃ³n, con un solo comando:

```bash
ansible-playbook -i ansible/inventories/gcp/hosts.yml ansible/main.yml
```

### Â¿QuÃ© hace este playbook?

1. âœ… **Habilita APIs de GCP** (Compute, Container, Container Registry)
2. âœ… **Crea infraestructura de red** (VPC custom y subnet)
3. âœ… **Crea cluster GKE** con autoscaling habilitado (2-10 nodos)
4. âœ… **Configura kubectl** con las credenciales del cluster
5. âœ… **Construye imÃ¡genes Docker** (backend y frontend)
6. âœ… **Sube imÃ¡genes a GCR** (Google Container Registry)
7. âœ… **Instala metrics-server** (si no estÃ¡ presente)
8. âœ… **Despliega la aplicaciÃ³n** vÃ­a Helm con HPA configurado
9. âœ… **Espera a que todo estÃ© listo** y muestra la IP externa

**Tiempo estimado:** 8-12 minutos

### Destruir toda la infraestructura

Cuando termines, destruye todo para evitar cargos:

```bash
ansible-playbook -i ansible/inventories/gcp/hosts.yml ansible/cleanup.yml
```

Esto elimina: cluster GKE, VPC, subnet, imÃ¡genes, load balancers, discos, etc.

---

## ï¿½ Requisitos Previos

### 1. Instalar herramientas necesarias

```bash
# Arch Linux
sudo pacman -S google-cloud-sdk kubectl helm docker ansible

# Ubuntu/Debian
sudo apt update
sudo apt install google-cloud-sdk kubectl helm docker.io ansible

# Iniciar Docker
sudo systemctl start docker
```

### 2. Configurar GCP

```bash
# Autenticar
gcloud auth login

# Configurar proyecto (reemplaza con tu project ID)
gcloud config set project todoapp-autoscaling-demo

# Habilitar billing (REQUERIDO para GKE)
# Visita: https://console.cloud.google.com/billing

# Configurar Docker para GCR
gcloud auth configure-docker
```

### 3. Configurar variables de Ansible

Edita `ansible/inventories/gcp/group_vars/all.yml`:

```yaml
# GCP Configuration
gcp_project_id: "tu-proyecto-id"        # â† CAMBIAR ESTO
gcp_region: "us-central1"
gcp_zone: "us-central1-a"

# GKE Cluster
gke_cluster_name: "todoapp-autoscaling-cluster"
gke_cluster_version: "latest"

# Autoscaling
gke_node_pool:
  min_node_count: 2
  max_node_count: 10
  machine_type: "e2-standard-2"
```

---

## ğŸš€ Despliegue Completo con Ansible

### Paso 1: Clonar repositorio

```bash
git clone https://github.com/LeoUNSA/CloudComputing.git
cd CloudComputing/ToDoApp
```

### Paso 2: Editar configuraciÃ³n

```bash
# Editar variables (especialmente gcp_project_id)
nano ansible/inventories/gcp/group_vars/all.yml
```

### Paso 3: Desplegar infraestructura

```bash
# Despliegue completo (un solo comando)
ansible-playbook -i ansible/inventories/gcp/hosts.yml ansible/main.yml

# Con output verbose (recomendado para la primera vez)
ansible-playbook -i ansible/inventories/gcp/hosts.yml ansible/main.yml -v
```

### Paso 4: Verificar despliegue

```bash
# Obtener credenciales del cluster
gcloud container clusters get-credentials todoapp-autoscaling-cluster \
  --zone=us-central1-a \
  --project=tu-proyecto-id

# Ver pods
kubectl get pods -n todoapp

# Ver servicios y obtener IP externa
kubectl get svc -n todoapp

# Ver HPA
kubectl get hpa -n todoapp

# Ver nodos
kubectl get nodes
```

### Paso 5: Acceder a la aplicaciÃ³n

```bash
# Obtener IP externa
kubectl get svc todoapp-frontend -n todoapp -o jsonpath='{.status.loadBalancer.ingress[0].ip}'

# Acceder en el browser
# http://<EXTERNAL-IP>:3000
```

---

## ğŸ”§ Estructura de Ansible

### Playbooks principales

```
ansible/
â”œâ”€â”€ main.yml                 # Playbook de despliegue
â”œâ”€â”€ cleanup.yml              # Playbook de limpieza
â”œâ”€â”€ inventories/
â”‚   â””â”€â”€ gcp/
â”‚       â”œâ”€â”€ hosts.yml        # Inventory (localhost)
â”‚       â””â”€â”€ group_vars/
â”‚           â””â”€â”€ all.yml      # Variables de configuraciÃ³n
â””â”€â”€ tasks/
    â”œâ”€â”€ setup-gke-cluster.yml       # Crear GKE y networking
    â”œâ”€â”€ build-and-push-images.yml   # Construir/subir imÃ¡genes
    â””â”€â”€ deploy-app.yml              # Desplegar app con Helm
```

### Variables configurables

Todas en `ansible/inventories/gcp/group_vars/all.yml`:

| Variable | DescripciÃ³n | Default |
|----------|-------------|---------|
| `gcp_project_id` | ID del proyecto GCP | `todoapp-autoscaling-demo` |
| `gcp_region` | RegiÃ³n de GCP | `us-central1` |
| `gcp_zone` | Zona de GCP | `us-central1-a` |
| `gke_cluster_name` | Nombre del cluster | `todoapp-autoscaling-cluster` |
| `min_node_count` | Nodos mÃ­nimos | `2` |
| `max_node_count` | Nodos mÃ¡ximos | `10` |
| `machine_type` | Tipo de mÃ¡quina | `e2-standard-2` |

### Personalizar el despliegue

```bash
# Cambiar proyecto por lÃ­nea de comandos
ansible-playbook -i ansible/inventories/gcp/hosts.yml ansible/main.yml \
  -e "gcp_project_id=mi-proyecto" \
  -e "gcp_region=europe-west1"

# Cambiar tamaÃ±o del cluster
ansible-playbook -i ansible/inventories/gcp/hosts.yml ansible/main.yml \
  -e "gke_node_pool.min_node_count=3" \
  -e "gke_node_pool.max_node_count=20"
```

---

## ğŸ§¹ Limpieza de Recursos

### Destruir todo con Ansible

```bash
# Eliminar cluster, VPC, imÃ¡genes, todo
ansible-playbook -i ansible/inventories/gcp/hosts.yml ansible/cleanup.yml

# Sin confirmaciÃ³n (para CI/CD)
ansible-playbook -i ansible/inventories/gcp/hosts.yml ansible/cleanup.yml \
  -e "confirm_user_input=yes"
```

### Verificar que no queden recursos

```bash
# Listar clusters
gcloud container clusters list --project=tu-proyecto-id

# Listar redes (excepto default)
gcloud compute networks list --project=tu-proyecto-id

# Listar discos
gcloud compute disks list --project=tu-proyecto-id
```

---

## ğŸ“¦ Stack TecnolÃ³gico

| Componente | TecnologÃ­a |
|------------|------------|
| **IaC** | Ansible (playbooks, no Terraform) |
| **Cloud** | Google Cloud Platform (GKE) |
| **OrquestaciÃ³n** | Kubernetes 1.28+ |
| **Package Manager** | Helm 3 |
| **Backend** | Node.js + Express + PostgreSQL |
| **Frontend** | React + Nginx |
| **Autoscaling** | HPA v2 + GKE Cluster Autoscaler |
| **Container Registry** | Google Container Registry (GCR) |
| **CI/CD** | GitHub Actions |

---

## ï¿½ IntegraciÃ³n Continua (CI/CD)

El proyecto incluye **GitHub Actions workflows** para automatizar build, testing y deployment.

### Workflows Disponibles

| Workflow | Trigger | DescripciÃ³n |
|----------|---------|-------------|
| **CI** | Push/PR a `main` o `develop` | Build, test, validaciÃ³n de manifiestos y security scan |
| **Deploy** | Push a `main` (o manual) | Despliegue completo a GKE con Ansible |
| **Cleanup** | Manual | DestrucciÃ³n de toda la infraestructura GCP |

### ConfiguraciÃ³n RÃ¡pida

1. **Crear Service Account de GCP:**
   ```bash
   gcloud iam service-accounts create github-actions-deployer \
     --project=tu-proyecto-id
   
   # Otorgar permisos
   gcloud projects add-iam-policy-binding tu-proyecto-id \
     --member="serviceAccount:github-actions-deployer@tu-proyecto-id.iam.gserviceaccount.com" \
     --role="roles/container.admin"
   
   # (Repetir para: compute.admin, storage.admin, iam.serviceAccountUser)
   
   # Crear clave JSON
   gcloud iam service-accounts keys create ~/gcp-key.json \
     --iam-account=github-actions-deployer@tu-proyecto-id.iam.gserviceaccount.com
   ```

2. **Configurar GitHub Secret:**
   - Ve a: `https://github.com/LeoUNSA/CloudComputing/settings/secrets/actions`
   - Agrega `GCP_SA_KEY` con el contenido de `gcp-key.json`

3. **Ejecutar workflows:**
   ```bash
   # Ver workflows disponibles
   gh workflow list
   
   # Deploy manual
   gh workflow run "CD - Deploy to GCP"
   
   # Cleanup manual
   gh workflow run "Cleanup - Destroy GCP Resources" -f confirm=destroy
   
   # Ver estado
   gh run list
   ```

**ğŸ“– GuÃ­a completa:** [.github/SETUP.md](.github/SETUP.md)

---

## ï¿½ğŸ”§ ConfiguraciÃ³n de Autoscaling

### HPA (Horizontal Pod Autoscaler)

Configurado en `helm/todoapp/templates/hpa.yaml`:

**Backend:**
- Min replicas: 2
- Max replicas: 10
- Target CPU: 50%
- Target Memory: 70%

**Frontend:**
- Min replicas: 2
- Max replicas: 8
- Target CPU: 60%
- Target Memory: 75%

### Cluster Autoscaler

Configurado en la creaciÃ³n del cluster GKE:

- Min nodes: 2
- Max nodes: 10
- Machine type: e2-standard-2 (2 vCPU, 8 GB RAM)

### Variables de ConfiguraciÃ³n

Todas las variables estÃ¡n centralizadas en:

```yaml
# ansible/inventories/gcp/group_vars/all.yml

gcp_project_id: "tu-proyecto-id"
gcp_region: "us-central1"
gcp_zone: "us-central1-a"

gke_node_pool:
  min_node_count: 2
  max_node_count: 10
  machine_type: "e2-standard-2"

autoscaling:
  backend:
    min_replicas: 2
    max_replicas: 10
    target_cpu_utilization: 50
    target_memory_utilization: 70
  frontend:
    min_replicas: 2
    max_replicas: 8
    target_cpu_utilization: 60
    target_memory_utilization: 75
```

---

## ğŸ§ª Prueba de Autoscaling

### Generar Carga

```bash
# Crear 5 generadores de carga
for i in {1..5}; do
  kubectl run load-gen-$i --image=busybox --restart=Never -n todoapp -- \
    /bin/sh -c "while true; do wget -q -O- http://todoapp-backend:5000/stress?duration=40000; done"
done
```

### Monitorear Escalado

```bash
# Terminal 1: Ver HPA
watch -n 2 'kubectl get hpa -n todoapp'

# Terminal 2: Ver nodos
watch -n 5 'kubectl get nodes'

# Terminal 3: Ver pods
watch -n 2 'kubectl get pods -n todoapp'
```

### Resultado Esperado

```
T=0:    2 pods backend, 2 nodos, CPU ~2%
        â†“ Generar carga
T=1min: CPU sube a 85%, HPA escala a 4 pods
T=2min: HPA escala a 6 pods
T=3min: HPA escala a 8 pods
T=4min: HPA escala a 10 pods (mÃ¡ximo)
T=5min: Algunos pods quedan "Pending" (sin recursos)
T=7min: Cluster Autoscaler aÃ±ade nodo 3
        Todos los pods pasan a "Running"
```

### Eliminar Carga

```bash
# Detener generadores
kubectl delete pod -n todoapp -l run=load-gen-1

# Scale-down automÃ¡tico (5-10 minutos)
# - HPA reduce pods gradualmente
# - Cluster Autoscaler elimina nodos infrautilizados
```

---

## ğŸ§ª Prueba de Autoscaling (Automatizado)

Hemos creado scripts automatizados para probar el autoscaling fÃ¡cilmente:

### OpciÃ³n 1: Test Completo Automatizado â­ (Recomendado)

Este script genera carga, monitorea el autoscaling y muestra estadÃ­sticas en tiempo real:

```bash
./load-testing/test-autoscaling.sh
```

**Â¿QuÃ© hace?**
- âœ… Muestra estado inicial (pods, nodos, HPA)
- âœ… Crea 8 generadores de carga automÃ¡ticamente
- âœ… Monitorea pods, nodos y HPA cada 10 segundos
- âœ… Muestra mÃ©tricas en tiempo real con colores
- âœ… Detecta cuando se aÃ±aden pods y nodos
- âœ… OpciÃ³n para limpiar generadores al final

**Personalizar:**
```bash
# MÃ¡s carga = mÃ¡s pods/nodos
LOAD_GENERATORS=12 ./load-testing/test-autoscaling.sh

# Test mÃ¡s largo
TEST_DURATION=900 ./load-testing/test-autoscaling.sh  # 15 minutos
```

### OpciÃ³n 2: Dashboard de Monitoreo

Para ver el estado en tiempo real (ejecuta en terminal separada):

```bash
./load-testing/monitor-autoscaling-dashboard.sh
```

**CaracterÃ­sticas:**
- ğŸ“Š Dashboard visual con colores
- ğŸ”„ ActualizaciÃ³n cada 3 segundos
- ğŸ“ˆ MÃ©tricas de HPA (CPU, Memory)
- ğŸ–¥ï¸ Estado de nodos
- ğŸ”¥ Detecta load generators activos

### OpciÃ³n 3: Manual

```bash
# 1. Generar carga
for i in {1..8}; do
  kubectl run load-generator-$i --image=busybox --restart=Never -n todoapp \
    --labels="role=load-generator" \
    -- /bin/sh -c "while true; do wget -q -O- http://todoapp-backend:5001/stress?duration=30000; done"
done

# 2. Monitorear (terminal separada)
./load-testing/monitor-autoscaling-dashboard.sh

# 3. Limpiar
kubectl delete pod -n todoapp -l role=load-generator
```

### Comportamiento Esperado

```
T=0min:  ğŸŸ¢ Estado inicial
         - 2 pods backend, 2 nodos, CPU ~5%

T=0min:  ğŸ”´ Iniciar carga (8 generadores)
         
T=1min:  ğŸ“ˆ HPA detecta CPU alto (>50%)
         - Backend: 2 â†’ 4 pods
         
T=2-3min: ğŸ“ˆ HPA escala continuamente
         - Backend: 4 â†’ 6 â†’ 8 â†’ 10 pods
         
T=4-5min: âš ï¸  Pods "Pending"
         - 10 pods (mÃ¡ximo HPA)
         - No hay recursos en nodos

T=7min:  ğŸ–¥ï¸  Cluster Autoscaler aÃ±ade nodo #3
         - Pods "Pending" â†’ "Running"
         
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

T=X:     ğŸ”µ Detener carga
         
T+2min:  ğŸ“‰ HPA reduce gradualmente
         - 10 â†’ 8 â†’ 6 â†’ 4 â†’ 2 pods
         
T+10min: ğŸ–¥ï¸  Cluster Autoscaler elimina nodos
         - Vuelve a 2 nodos (mÃ­nimo)
```

**ğŸ“– MÃ¡s detalles:** `docs/05-MANUAL-AUTOSCALING-TEST.md`

**ï¿½ DocumentaciÃ³n detallada:** Ver `docs/05-MANUAL-AUTOSCALING-TEST.md`

---

## ï¿½ğŸ“ Estructura del Proyecto

```
ToDoApp/
â”œâ”€â”€ ansible/                          # â­ Infrastructure as Code (lo importante)
â”‚   â”œâ”€â”€ main.yml                      # Playbook de despliegue
â”‚   â”œâ”€â”€ cleanup.yml                   # Playbook de limpieza
â”‚   â”œâ”€â”€ inventories/gcp/
â”‚   â”‚   â”œâ”€â”€ hosts.yml                 # Inventory (localhost)
â”‚   â”‚   â””â”€â”€ group_vars/
â”‚   â”‚       â””â”€â”€ all.yml               # âš™ï¸ Variables de configuraciÃ³n
â”‚   â””â”€â”€ tasks/
â”‚       â”œâ”€â”€ setup-gke-cluster.yml     # Crea GKE, VPC, subnet
â”‚       â”œâ”€â”€ build-and-push-images.yml # Build/push a GCR
â”‚       â””â”€â”€ deploy-app.yml            # Deploy con Helm + HPA
â”‚
â”œâ”€â”€ .github/workflows/                # CI/CD con GitHub Actions
â”‚   â”œâ”€â”€ ci.yml                        # Build/test automÃ¡tico
â”‚   â”œâ”€â”€ deploy-gcp.yml                # Deploy con Ansible
â”‚   â””â”€â”€ cleanup-gcp.yml               # Cleanup de recursos
â”‚
â”œâ”€â”€ helm/todoapp/                     # Helm Chart de la aplicaciÃ³n
â”‚   â”œâ”€â”€ values.yaml                   # ConfiguraciÃ³n
â”‚   â”œâ”€â”€ values-dev.yaml               # Config para desarrollo
â”‚   â””â”€â”€ templates/
â”‚       â”œâ”€â”€ hpa.yaml                  # Horizontal Pod Autoscaler
â”‚       â”œâ”€â”€ backend-deployment.yaml
â”‚       â”œâ”€â”€ frontend-deployment.yaml
â”‚       â””â”€â”€ postgres-deployment.yaml
â”‚
â”œâ”€â”€ backend/                          # API Node.js + Express
â”‚   â”œâ”€â”€ server.js                     # Incluye endpoint /stress
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ frontend/                         # React SPA
â”‚   â”œâ”€â”€ src/App.js
â”‚   â”œâ”€â”€ nginx.conf                    # Reverse proxy a backend
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ docs/                             # DocumentaciÃ³n detallada
â”‚   â”œâ”€â”€ 01-ANSIBLE-DEPLOYMENT.md
â”‚   â”œâ”€â”€ 02-AUTOSCALING-MECHANISMS.md
â”‚   â”œâ”€â”€ 05-MANUAL-AUTOSCALING-TEST.md
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ load-testing/                     # Scripts de pruebas de carga
â”‚   â”œâ”€â”€ simple-load-test.sh
â”‚   â”œâ”€â”€ monitor-autoscaling.sh
â”‚   â””â”€â”€ extreme-load-test.sh
â”‚
â”œâ”€â”€ ANSIBLE-DEPLOYMENT.md             # ğŸ“– GuÃ­a completa de Ansible
â””â”€â”€ README.md                         # Este archivo
```

---

---

## ï¿½ DocumentaciÃ³n

- **[ANSIBLE-DEPLOYMENT.md](ANSIBLE-DEPLOYMENT.md)** - GuÃ­a completa de despliegue con Ansible
- **[.github/SETUP.md](.github/SETUP.md)** - Setup de GitHub Actions CI/CD
- **[docs/01-ANSIBLE-DEPLOYMENT.md](docs/01-ANSIBLE-DEPLOYMENT.md)** - Detalles tÃ©cnicos de Ansible
- **[docs/02-AUTOSCALING-MECHANISMS.md](docs/02-AUTOSCALING-MECHANISMS.md)** - CÃ³mo funciona el autoscaling
- **[docs/05-MANUAL-AUTOSCALING-TEST.md](docs/05-MANUAL-AUTOSCALING-TEST.md)** - Pruebas manuales de autoscaling

---

## ğŸš¨ Troubleshooting

### Error: "Billing not enabled"
```bash
# Habilitar billing en: https://console.cloud.google.com/billing
gcloud billing projects link tu-proyecto-id --billing-account=BILLING_ID
```

### Error: "API not enabled"
```bash
# Ansible lo hace automÃ¡ticamente, pero manualmente:
gcloud services enable compute.googleapis.com
gcloud services enable container.googleapis.com
```

### Error: "Permission denied"
```bash
# Verificar autenticaciÃ³n
gcloud auth list
gcloud auth login
```

### Cluster no escala
```bash
# Verificar metrics-server
kubectl get deployment metrics-server -n kube-system

# Verificar HPA
kubectl describe hpa -n todoapp

# Ver eventos del cluster autoscaler
kubectl get events -n kube-system | grep cluster-autoscaler
```

---

## ğŸ’° GestiÃ³n de Costos

### EstimaciÃ³n de costos (GCP us-central1)

| Recurso | ConfiguraciÃ³n | Costo/hora aprox. |
|---------|---------------|-------------------|
| GKE cluster | Gratis | $0.00 |
| 2 nodos e2-standard-2 | 2 vCPU, 8GB RAM cada uno | ~$0.13 |
| Load Balancer | 1 regla | ~$0.025 |
| Persistent Disk | 10GB SSD | ~$0.0002 |
| **Total** | **MÃ­nimo** | **~$0.16/hora** |

**Costo diario mÃ­nimo:** ~$3.84  
**Costo mensual mÃ­nimo (24/7):** ~$115

### Reducir costos

```bash
# 1. Destruir cuando no uses (RECOMENDADO)
ansible-playbook -i ansible/inventories/gcp/hosts.yml ansible/cleanup.yml

# 2. Reducir nÃºmero de nodos mÃ­nimos
# Editar: ansible/inventories/gcp/group_vars/all.yml
gke_node_pool:
  min_node_count: 1  # En vez de 2
  max_node_count: 5
```

### Monitorear costos

```bash
# Ver gastos actuales
gcloud billing accounts list
gcloud billing projects describe tu-proyecto-id

# Configurar alertas: https://console.cloud.google.com/billing/alerts
```

---

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/amazing-feature`)
3. Commit tus cambios (`git commit -m 'Add amazing feature'`)
4. Push a la rama (`git push origin feature/amazing-feature`)
5. Abre un Pull Request

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT.

---

## âœ¨ Autor

**Leo** - [@LeoUNSA](https://github.com/LeoUNSA)

---

## ï¿½ Agradecimientos

- Google Cloud Platform por la infraestructura
- Kubernetes por la orquestaciÃ³n
- Ansible por la automatizaciÃ³n IaC
- Helm por el package management

---

## ğŸ“ Soporte

Â¿Problemas con el despliegue? Abre un issue en GitHub:
https://github.com/LeoUNSA/CloudComputing/issues

- **VPC Network**: `todoapp-network` (10.0.0.0/24)
- **Service Frontend**: LoadBalancer (expuesto a Internet)
- **Service Backend**: ClusterIP (solo interno)
- **Service Postgres**: ClusterIP (solo interno)
- **Nginx Reverse Proxy**: `/api/*` â†’ `http://todoapp-backend:5000/*`

---

## ğŸ” VerificaciÃ³n

```bash
# Ver estado del cluster
kubectl get nodes

# Ver pods
kubectl get pods -n todoapp

# Ver HPA
kubectl get hpa -n todoapp

# Ver services
kubectl get svc -n todoapp

# Ver mÃ©tricas
kubectl top pods -n todoapp
kubectl top nodes

# Logs de un pod
kubectl logs -n todoapp <pod-name>

# Acceder a la aplicaciÃ³n
kubectl get svc todoapp-frontend -n todoapp
# http://<EXTERNAL-IP>:3000
```

---

## ğŸ—‘ï¸ Limpieza

```bash
# OpciÃ³n 1: Ansible (recomendado)
ansible-playbook -i ansible/inventories/gcp/hosts.yml ansible/cleanup.yml

# OpciÃ³n 2: Manual
helm uninstall todoapp -n todoapp
kubectl delete namespace todoapp
gcloud container clusters delete todoapp-autoscaling-cluster --zone=us-central1-a --quiet
gcloud compute networks subnets delete todoapp-subnet --region=us-central1 --quiet
gcloud compute networks delete todoapp-network --quiet
```

---

## ğŸ“š DocumentaciÃ³n Extendida

Para informaciÃ³n detallada, consultar:

- **[SETUP-GUIDE.md](SETUP-GUIDE.md)** - GuÃ­a completa de configuraciÃ³n
- **[docs/01-ANSIBLE-DEPLOYMENT.md](docs/01-ANSIBLE-DEPLOYMENT.md)** - Funcionamiento de Ansible
- **[docs/02-AUTOSCALING-MECHANISMS.md](docs/02-AUTOSCALING-MECHANISMS.md)** - HPA y Cluster Autoscaler
- **[docs/03-CLOUD-ARCHITECTURE.md](docs/03-CLOUD-ARCHITECTURE.md)** - Arquitectura cloud
- **[docs/04-DEPLOYMENT-COMMANDS.md](docs/04-DEPLOYMENT-COMMANDS.md)** - Comandos de despliegue
- **[docs/05-MANUAL-AUTOSCALING-TEST.md](docs/05-MANUAL-AUTOSCALING-TEST.md)** - Pruebas de autoscaling
- **[docs/06-LOAD-GENERATION-INTERNALS.md](docs/06-LOAD-GENERATION-INTERNALS.md)** - GeneraciÃ³n de trÃ¡fico

---

## âš™ï¸ ConfiguraciÃ³n Personalizada

### Cambiar RegiÃ³n/Zona

```yaml
# ansible/inventories/gcp/group_vars/all.yml
gcp_region: "europe-west1"
gcp_zone: "europe-west1-b"
```

### Ajustar Autoscaling

```yaml
# MÃ¡s agresivo
autoscaling:
  backend:
    min_replicas: 1
    max_replicas: 20
    target_cpu_utilization: 30  # Escala mÃ¡s rÃ¡pido

# MÃ¡s conservador
autoscaling:
  backend:
    min_replicas: 3
    max_replicas: 6
    target_cpu_utilization: 80  # Tolera mÃ¡s carga
```

### Cambiar Tipo de MÃ¡quina

```yaml
gke_node_pool:
  machine_type: "e2-standard-4"  # 4 vCPU, 16 GB RAM
  # o
  machine_type: "e2-highcpu-8"   # 8 vCPU, 8 GB RAM
```

---

## ğŸ› ï¸ Troubleshooting

### HPA No Escala

```bash
# Verificar metrics-server
kubectl top pods -n todoapp

# Si falla, reinstalar
helm upgrade --install metrics-server metrics-server/metrics-server \
  --namespace kube-system \
  --set args={--kubelet-insecure-tls}
```

### Cluster Autoscaler No AÃ±ade Nodos

```bash
# Ver logs del autoscaler
kubectl logs -n kube-system -l k8s-app=cluster-autoscaler

# Verificar configuraciÃ³n
gcloud container clusters describe todoapp-autoscaling-cluster \
  --zone=us-central1-a \
  --format="value(autoscaling)"
```

### Pods en CrashLoopBackOff

```bash
# Ver logs
kubectl logs <pod-name> -n todoapp

# Describir pod
kubectl describe pod <pod-name> -n todoapp

# Ver eventos
kubectl get events -n todoapp --sort-by='.lastTimestamp'
```

---

## ğŸ“Š MÃ©tricas y Costos

### Recursos Utilizados

**Estado inicial (mÃ­nimo)**:
- 2 nodos e2-standard-2
- 2 pods backend
- 2 pods frontend
- 1 pod postgres
- **Costo estimado**: ~$100-120 USD/mes

**Estado con carga (mÃ¡ximo)**:
- 10 nodos e2-standard-2
- 10 pods backend
- 8 pods frontend
- 1 pod postgres
- **Costo estimado**: ~$500-600 USD/mes (solo durante carga)

**Ventaja del autoscaling**: Pagas solo por lo que usas, escala automÃ¡ticamente segÃºn demanda.

---

## ğŸ“ Conceptos Clave

### HPA (Horizontal Pod Autoscaler)
Escala el **nÃºmero de rÃ©plicas** de un Deployment basÃ¡ndose en mÃ©tricas (CPU, Memory). Definido en `helm/todoapp/templates/hpa.yaml`.

### Cluster Autoscaler
Escala el **nÃºmero de nodos** del cluster cuando hay pods en estado Pending por falta de recursos. Configurado al crear el cluster GKE.

### Ansible como IaC
Automatiza la creaciÃ³n de infraestructura usando comandos `gcloud` y `kubectl` dentro de playbooks YAML. Alternativa a Terraform, mÃ¡s simple para este caso de uso.

### Nginx Reverse Proxy
El frontend usa nginx para hacer proxy de `/api/*` al backend, evitando problemas de CORS y simplificando la configuraciÃ³n.

---

## ğŸ¤ AplicaciÃ³n de Ejemplo

La aplicaciÃ³n ToDo es un ejemplo simple para demostrar autoscaling. Incluye:

- **Backend**: API REST con endpoints CRUD + `/stress` para load testing
- **Frontend**: Interfaz React para gestionar tareas
- **Database**: PostgreSQL con datos de ejemplo

El enfoque principal es la **infraestructura y autoscaling**, no la funcionalidad de la aplicaciÃ³n.

---

## ğŸ“œ Licencia

Proyecto educacional - Uso libre

---

## ğŸ”— Enlaces Ãštiles

- [DocumentaciÃ³n GKE Autoscaling](https://cloud.google.com/kubernetes-engine/docs/concepts/horizontalpodautoscaler)
- [HPA Walkthrough](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/)
- [Ansible Documentation](https://docs.ansible.com/)
- [Helm Charts](https://helm.sh/docs/topics/charts/)
