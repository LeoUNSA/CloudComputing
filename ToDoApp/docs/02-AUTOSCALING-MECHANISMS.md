# Mecanismos de Autoscaling en Kubernetes y GCP

## Ãndice
1. [IntroducciÃ³n al Autoscaling](#introducciÃ³n-al-autoscaling)
2. [HPA - Horizontal Pod Autoscaler](#hpa---horizontal-pod-autoscaler)
3. [Cluster Autoscaler](#cluster-autoscaler)
4. [IntegraciÃ³n y CoordinaciÃ³n](#integraciÃ³n-y-coordinaciÃ³n)
5. [ConfiguraciÃ³n en este Proyecto](#configuraciÃ³n-en-este-proyecto)
6. [PolÃ­ticas de Escalado](#polÃ­ticas-de-escalado)
7. [Monitoreo y ValidaciÃ³n](#monitoreo-y-validaciÃ³n)

---

## IntroducciÃ³n al Autoscaling

El autoscaling en Kubernetes tiene **dos niveles complementarios**:

| Nivel | Componente | Escala | Responsabilidad |
|-------|-----------|---------|-----------------|
| **Pod** | HPA (Horizontal Pod Autoscaler) | Pods | Ajusta rÃ©plicas de un Deployment |
| **Nodo** | Cluster Autoscaler | Nodos | AÃ±ade/elimina nodos del cluster |

### Â¿Por QuÃ© Autoscaling?

**Beneficios**:
- ğŸ’° **Costos**: Paga solo por recursos usados
- ğŸ“ˆ **Performance**: Escala automÃ¡ticamente ante demanda
- ğŸ›¡ï¸ **Resiliencia**: Distribuye carga en mÃºltiples pods/nodos
- ğŸŒ™ **Eficiencia**: Reduce recursos en horarios de baja demanda

**Escenario de Ejemplo**:
```
09:00 - Baja demanda â†’ 2 pods, 2 nodos
12:00 - Pico de trÃ¡fico â†’ 10 pods, 4 nodos (auto-scaled)
18:00 - Demanda normal â†’ 3 pods, 2 nodos (scale-down)
```

---

## HPA - Horizontal Pod Autoscaler

### Â¿QuÃ© es HPA?

HPA es un controlador de Kubernetes que **ajusta automÃ¡ticamente el nÃºmero de rÃ©plicas de pods** en un Deployment, ReplicaSet o StatefulSet basÃ¡ndose en mÃ©tricas observadas.

### Arquitectura HPA

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. MÃ©tricas recolectadas cada 15 segundos                  â”‚
â”‚     metrics-server â†’ CPU/Memory de pods                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. HPA Controller calcula rÃ©plicas deseadas                â”‚
â”‚     Formula: desiredReplicas = ceil[currentReplicas *       â”‚
â”‚              (currentMetric / targetMetric)]                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Aplicar scale-up/down con polÃ­ticas                     â”‚
â”‚     - Respetar stabilizationWindowSeconds                   â”‚
â”‚     - Aplicar limitadores de velocidad                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Deployment actualiza nÃºmero de rÃ©plicas                 â”‚
â”‚     - Crear nuevos pods (scale-up)                          â”‚
â”‚     - Terminar pods excedentes (scale-down)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ConfiguraciÃ³n HPA en este Proyecto

**UbicaciÃ³n**: `helm/todoapp/templates/hpa.yaml`

#### HPA para Backend

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: todoapp-backend-hpa
  namespace: {{ .Values.namespace }}
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: todoapp-backend
  
  minReplicas: {{ .Values.autoscaling.backend.minReplicas }}      # 2
  maxReplicas: {{ .Values.autoscaling.backend.maxReplicas }}      # 10
  
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: {{ .Values.autoscaling.backend.targetCPUUtilizationPercentage }}  # 50%
  
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: {{ .Values.autoscaling.backend.targetMemoryUtilizationPercentage }}  # 70%
  
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300  # Espera 5 minutos antes de scale-down
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60              # MÃ¡x 50% reducciÃ³n por minuto
      - type: Pods
        value: 2
        periodSeconds: 60              # MÃ¡x 2 pods eliminados por minuto
      selectPolicy: Min                # Usa la polÃ­tica mÃ¡s conservadora
    
    scaleUp:
      stabilizationWindowSeconds: 0    # Scale-up inmediato
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15              # Puede duplicar pods en 15s
      - type: Pods
        value: 4
        periodSeconds: 15              # MÃ¡x 4 pods nuevos cada 15s
      selectPolicy: Max                # Usa la polÃ­tica mÃ¡s agresiva
```

#### HPA para Frontend

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: todoapp-frontend-hpa
  namespace: {{ .Values.namespace }}
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: todoapp-frontend
  
  minReplicas: {{ .Values.autoscaling.frontend.minReplicas }}     # 2
  maxReplicas: {{ .Values.autoscaling.frontend.maxReplicas }}     # 8
  
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: {{ .Values.autoscaling.frontend.targetCPUUtilizationPercentage }}  # 60%
  
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: {{ .Values.autoscaling.frontend.targetMemoryUtilizationPercentage }}  # 75%
  
  behavior:
    # Mismo comportamiento que backend
    scaleDown:
      stabilizationWindowSeconds: 300
      # ...
```

### Variables de ConfiguraciÃ³n HPA

**UbicaciÃ³n**: `ansible/inventories/gcp/group_vars/all.yml`

```yaml
autoscaling:
  backend:
    min_replicas: 2                    # MÃ­nimo siempre activo
    max_replicas: 10                   # LÃ­mite superior
    target_cpu_utilization: 50         # Scale-up si CPU > 50%
    target_memory_utilization: 70      # Scale-up si Memory > 70%
  
  frontend:
    min_replicas: 2
    max_replicas: 8
    target_cpu_utilization: 60         # Frontend tolera mÃ¡s CPU
    target_memory_utilization: 75
```

### FÃ³rmula de CÃ¡lculo de RÃ©plicas

```
desiredReplicas = ceil[currentReplicas Ã— (currentMetric / targetMetric)]
```

**Ejemplo real** (Backend con CPU):
```
SituaciÃ³n inicial:
- currentReplicas = 2
- targetCPU = 50%
- currentCPU = 85% (promedio de todos los pods)

CÃ¡lculo:
desiredReplicas = ceil[2 Ã— (85 / 50)]
                = ceil[2 Ã— 1.7]
                = ceil[3.4]
                = 4 pods

Resultado: HPA escala de 2 â†’ 4 pods
```

### Tipos de MÃ©tricas Soportadas

| Tipo | DescripciÃ³n | Ejemplo |
|------|-------------|---------|
| **Resource** | CPU, Memory del pod | `cpu.averageUtilization: 50%` |
| **Pods** | MÃ©tricas custom por pod | `http_requests_per_second: 100` |
| **Object** | MÃ©tricas de objetos K8s | `ingress.requests_per_second` |
| **External** | MÃ©tricas externas | `sqs_queue_length` (AWS SQS) |

**En este proyecto** solo usamos **Resource** (CPU y Memory).

---

## Cluster Autoscaler

### Â¿QuÃ© es Cluster Autoscaler?

Cluster Autoscaler es un componente que **aÃ±ade o elimina nodos** en el cluster basÃ¡ndose en:

1. **Pods pendientes**: Pods que no pueden programarse por falta de recursos
2. **Nodos infrautilizados**: Nodos con baja utilizaciÃ³n durante periodo prolongado

### Arquitectura Cluster Autoscaler

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Escenario 1: SCALE-UP (aÃ±adir nodos)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. HPA crea nuevos pods (demanda alta)
                   â†“
2. Scheduler intenta asignar pods a nodos
                   â†“
3. No hay recursos â†’ Pods quedan en estado "Pending"
                   â†“
4. Cluster Autoscaler detecta pods Pending (cada 10s)
                   â†“
5. Calcula nÃºmero de nodos necesarios
                   â†“
6. Solicita nuevos nodos al proveedor cloud (GCP)
                   â†“
7. Nodos se aprovisionan (2-3 minutos)
                   â†“
8. Scheduler asigna pods pendientes a nuevos nodos
                   â†“
9. Pods pasan de Pending â†’ Running

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Escenario 2: SCALE-DOWN (eliminar nodos)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. HPA reduce nÃºmero de pods (demanda baja)
                   â†“
2. Algunos nodos quedan con poca carga (<50% recursos)
                   â†“
3. Cluster Autoscaler espera 10 minutos (unneeded-time)
                   â†“
4. Si carga sigue baja, marca nodo como "unneeded"
                   â†“
5. Drena pods del nodo (los mueve a otros nodos)
                   â†“
6. Elimina nodo del cluster
                   â†“
7. GCP libera la VM (ahorro de costos)
```

### ConfiguraciÃ³n en GKE

**UbicaciÃ³n**: `ansible/tasks/setup-gke-cluster.yml`

```yaml
- name: Create GKE cluster with autoscaling
  command: >
    gcloud container clusters create {{ gke_cluster_name }}
    --zone={{ gcp_zone }}
    --num-nodes={{ gke_node_pool.initial_node_count }}     # 2 nodos iniciales
    --min-nodes={{ gke_node_pool.min_node_count }}         # MÃ­nimo: 2
    --max-nodes={{ gke_node_pool.max_node_count }}         # MÃ¡ximo: 10
    --enable-autoscaling                                   # â† ACTIVA CLUSTER AUTOSCALER
    --machine-type={{ gke_node_pool.machine_type }}        # e2-standard-2
    --enable-autorepair
    --enable-autoupgrade
```

### Variables de Node Pool

**UbicaciÃ³n**: `ansible/inventories/gcp/group_vars/all.yml`

```yaml
gke_node_pool:
  initial_node_count: 2    # Nodos al crear cluster
  min_node_count: 2        # Nunca menos de 2 nodos
  max_node_count: 10       # LÃ­mite superior (escala hasta 10)
  machine_type: "e2-standard-2"
  disk_size_gb: 50
```

### ParÃ¡metros Clave del Cluster Autoscaler

| ParÃ¡metro | Valor | DescripciÃ³n |
|-----------|-------|-------------|
| `scan-interval` | 10s | Frecuencia de evaluaciÃ³n |
| `scale-down-unneeded-time` | 10m | Tiempo antes de eliminar nodo |
| `scale-down-delay-after-add` | 10m | Espera tras aÃ±adir nodo |
| `scale-down-utilization-threshold` | 0.5 | Umbral de utilizaciÃ³n (50%) |
| `max-node-provision-time` | 15m | Timeout para provisionar nodo |

### Condiciones para Scale-Down

Un nodo se elimina **solo si**:
1. âœ… UtilizaciÃ³n < 50% por mÃ¡s de 10 minutos
2. âœ… Todos sus pods pueden moverse a otros nodos
3. âœ… No tiene pods con `PodDisruptionBudget` que impida el drain
4. âœ… No tiene pods con `local-storage` crÃ­tico
5. âœ… Cluster tiene > min_node_count nodos

---

## IntegraciÃ³n y CoordinaciÃ³n

### InteracciÃ³n HPA â†” Cluster Autoscaler

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 1: Demanda aumenta gradualmente                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

T=0:    2 pods backend, 2 nodos (recursos suficientes)
        CPU: 30% â†’ HPA no actÃºa

T=2min: CPU: 65% (> 50% target)
        â†“
        HPA escala: 2 â†’ 4 pods
        â†“
        4 pods asignados a 2 nodos (aÃºn caben)
        CPU por nodo: 80%

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 2: Demanda aumenta fuertemente                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

T=5min: CPU: 85% (muy alto)
        â†“
        HPA escala: 4 â†’ 8 pods
        â†“
        Scheduler intenta asignar 4 pods nuevos
        â†“
        Solo caben 2 pods mÃ¡s (CPU/Memory lÃ­mite)
        â†“
        2 pods quedan en estado "Pending"
        â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  CLUSTER AUTOSCALER ACTÃšA            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
        Detecta 2 pods Pending (cada 10s)
        â†“
        Calcula: necesita 1 nodo adicional
        â†“
        Solicita nodo a GCP
        â†“
        Espera 2-3 min (aprovisionamiento)
        â†“
        Nodo 3 se une al cluster
        â†“
        Scheduler asigna los 2 pods Pending al nodo 3
        â†“
        8 pods Running distribuidos en 3 nodos

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 3: Demanda disminuye                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

T=20min: Carga eliminada, CPU: 5%
         â†“
         HPA espera stabilizationWindow (5 min)
         â†“
T=25min: HPA escala: 8 â†’ 3 pods
         â†“
         Nodo 3 queda con 0 pods asignados
         â†“
         Cluster Autoscaler espera 10 min
         â†“
T=35min: Si nodo sigue vacÃ­o, se elimina
         â†“
         Cluster vuelve a 2 nodos
```

### Caso Real del Proyecto

**DemostraciÃ³n ejecutada**:

```bash
# Estado inicial
$ kubectl get hpa -n todoapp
NAME                  REFERENCE                  TARGETS    MINPODS   MAXPODS   REPLICAS
todoapp-backend-hpa   Deployment/todoapp-backend 2%/50%     2         10        2

$ kubectl get nodes
NAME                                       STATUS   ROLES    AGE
gke-...-default-pool-abc123                Ready    <none>   10m
gke-...-default-pool-def456                Ready    <none>   10m
# 2 nodos iniciales

# Generamos carga (10 generadores)
$ kubectl run load-gen-{1..10} --image=busybox ...

# DespuÃ©s de 3 minutos
$ kubectl get hpa -n todoapp
NAME                  REFERENCE                  TARGETS    MINPODS   MAXPODS   REPLICAS
todoapp-backend-hpa   Deployment/todoapp-backend 95%/50%    2         10        10
# â†‘ HPA escalÃ³ a 10 pods (mÃ¡ximo)

$ kubectl get pods -n todoapp | grep backend
todoapp-backend-xxx   Running   node-1
todoapp-backend-yyy   Running   node-1
todoapp-backend-zzz   Running   node-2
...
todoapp-backend-www   Pending             # â† 1 pod sin recursos
# â†‘ 9 pods running, 1 pending

# DespuÃ©s de 2 minutos (Cluster Autoscaler actÃºa)
$ kubectl get nodes
NAME                                       STATUS   ROLES    AGE
gke-...-default-pool-abc123                Ready    <none>   13m
gke-...-default-pool-def456                Ready    <none>   13m
gke-...-default-pool-ghi789                Ready    <none>   30s
# â†‘ Nodo 3 aÃ±adido automÃ¡ticamente

$ kubectl get pods -n todoapp -o wide
...
todoapp-backend-www   Running   node-3
# â†‘ Pod pendiente ahora en nodo 3
```

---

## PolÃ­ticas de Escalado

### Scale Behaviors (HPA v2)

#### Scale-Down (ReducciÃ³n de Pods)

```yaml
scaleDown:
  stabilizationWindowSeconds: 300  # 5 minutos de ventana
  policies:
  - type: Percent    # PolÃ­tica 1: Porcentual
    value: 50
    periodSeconds: 60
    # MÃ¡ximo 50% de reducciÃ³n cada 60 segundos
  
  - type: Pods       # PolÃ­tica 2: Absoluta
    value: 2
    periodSeconds: 60
    # MÃ¡ximo 2 pods eliminados cada 60 segundos
  
  selectPolicy: Min  # Usa la mÃ¡s conservadora
```

**Ejemplo**:
```
SituaciÃ³n: 10 pods â†’ necesita reducir a 4 pods

PolÃ­tica Percent: 10 Ã— 50% = 5 pods/min â†’ 2 minutos total
PolÃ­tica Pods:    2 pods/min           â†’ 3 minutos total

selectPolicy: Min â†’ elige Pods policy (mÃ¡s lenta)

Timeline:
T=0:   10 pods
T=60s:  8 pods (-2)
T=120s: 6 pods (-2)
T=180s: 4 pods (-2)
```

#### Scale-Up (Aumento de Pods)

```yaml
scaleUp:
  stabilizationWindowSeconds: 0  # Sin espera (respuesta inmediata)
  policies:
  - type: Percent
    value: 100       # Puede duplicar pods
    periodSeconds: 15
  
  - type: Pods
    value: 4
    periodSeconds: 15
  
  selectPolicy: Max  # Usa la mÃ¡s agresiva
```

**Ejemplo**:
```
SituaciÃ³n: 2 pods â†’ necesita 10 pods (carga alta)

PolÃ­tica Percent: 2 Ã— 100% = 4 pods cada 15s
PolÃ­tica Pods:    4 pods cada 15s

selectPolicy: Max â†’ ambas iguales en este caso

Timeline:
T=0:   2 pods
T=15s: 6 pods (+4)
T=30s: 10 pods (+4)
```

### Evitar Flapping (Oscilaciones)

**Problema**: Sin `stabilizationWindow`, HPA puede oscilar:
```
10:00 â†’ 2 pods (CPU bajo)
10:05 â†’ 6 pods (CPU alto por startup)
10:10 â†’ 2 pods (CPU se normaliza)
10:15 â†’ 6 pods (CPU alto de nuevo)
```

**SoluciÃ³n**: `stabilizationWindowSeconds: 300`
```
10:00 â†’ 2 pods (CPU bajo)
10:05 â†’ CPU sube (HPA considera Ãºltimos 5 min)
10:10 â†’ CPU promedio sigue bajo â†’ no escala
```

---

## Monitoreo y ValidaciÃ³n

### Comandos de Monitoreo HPA

```bash
# Ver estado actual de HPA
kubectl get hpa -n todoapp

# Salida:
# NAME                  REFERENCE                  TARGETS         MINPODS   MAXPODS   REPLICAS
# todoapp-backend-hpa   Deployment/todoapp-backend 35%/50%, 45%/70%   2         10        3
#                                                  â†‘CPU    â†‘Memory

# Ver detalles y eventos de HPA
kubectl describe hpa todoapp-backend-hpa -n todoapp

# Ver mÃ©tricas en tiempo real
kubectl top pods -n todoapp

# Monitoreo continuo (cada 2s)
watch kubectl get hpa -n todoapp
```

### Comandos de Monitoreo Cluster Autoscaler

```bash
# Ver nodos del cluster
kubectl get nodes

# Ver detalles de un nodo (capacidad, utilizaciÃ³n)
kubectl describe node <node-name>

# Ver eventos del cluster (incluye CA events)
kubectl get events -n kube-system | grep cluster-autoscaler

# Ver pods por nodo
kubectl get pods -n todoapp -o wide

# Ver logs del Cluster Autoscaler
kubectl logs -f -n kube-system deployment/cluster-autoscaler
```

### MÃ©tricas Clave

| MÃ©trica | Comando | QuÃ© observar |
|---------|---------|--------------|
| **CPU por Pod** | `kubectl top pods -n todoapp` | > target â†’ scale-up |
| **RÃ©plicas actuales** | `kubectl get hpa -n todoapp` | REPLICAS columna |
| **Pods Pending** | `kubectl get pods -n todoapp` | Estado Pending |
| **NÃºmero de nodos** | `kubectl get nodes` | Incremento/decremento |
| **UtilizaciÃ³n nodo** | `kubectl describe node <name>` | Allocated resources |

### Validar ConfiguraciÃ³n

```bash
# Verificar HPA estÃ¡ activo
kubectl get hpa -n todoapp

# Verificar metrics-server funciona
kubectl top nodes
kubectl top pods -n todoapp

# Verificar Cluster Autoscaler habilitado
gcloud container clusters describe todoapp-autoscaling-cluster \
  --zone=us-central1-a \
  --format="value(autoscaling)"

# Salida esperada:
# Autoscaling profile: BALANCED
# Enabled: True
# Min nodes: 2
# Max nodes: 10
```

---

## ConclusiÃ³n

### Resumen de Componentes

| Componente | QuÃ© escala | Trigger | Tiempo |
|------------|-----------|---------|--------|
| **HPA** | Pods | CPU/Memory > target | 15-60s |
| **Cluster Autoscaler** | Nodos | Pods Pending | 2-3 min |
| **metrics-server** | - | Provee mÃ©tricas | 15s refresh |

### Mejores PrÃ¡cticas

1. âœ… **Configurar requests/limits** en Deployments (HPA necesita estos valores)
2. âœ… **Usar stabilizationWindow** para evitar flapping
3. âœ… **Monitorear eventos** para troubleshooting
4. âœ… **Probar scale-down** (suele ser mÃ¡s problemÃ¡tico)
5. âœ… **Configurar PodDisruptionBudgets** para evitar downtime

### Limitaciones

- âŒ HPA no puede escalar a 0 pods (min: 1)
- âŒ Cluster Autoscaler tarda minutos (no segundos)
- âŒ Scale-down es conservador (10 min espera)
- âŒ Solo mÃ©tricas Resource sin custom metrics en esta versiÃ³n

Este sistema de autoscaling dual proporciona elasticidad completa desde pods hasta infraestructura, optimizando costos y performance automÃ¡ticamente.
